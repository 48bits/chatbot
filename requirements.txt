llama-cpp-python>=0.2.38
requests>=2.31.0 